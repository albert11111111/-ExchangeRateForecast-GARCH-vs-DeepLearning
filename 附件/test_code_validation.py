#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ä»£ç é€»è¾‘éªŒè¯è„šæœ¬
================

æµ‹è¯•ä¿®å¤åçš„æ•°ç»„é•¿åº¦ä¸€è‡´æ€§é—®é¢˜ï¼Œæ— éœ€è¿è¡Œå®Œæ•´çš„ARIMA+GARCHç³»ç»Ÿ
"""

import numpy as np
import os

def test_array_length_consistency():
    """æµ‹è¯•æ•°ç»„é•¿åº¦ä¸€è‡´æ€§ä¿®å¤"""
    print("="*60)
    print("æµ‹è¯•1: æ•°ç»„é•¿åº¦ä¸€è‡´æ€§ä¿®å¤")
    print("="*60)
    
    # æ¨¡æ‹Ÿé—®é¢˜åœºæ™¯ï¼šé¢„æµ‹çª—å£å¯èƒ½è¶…å‡ºæ•°æ®è¾¹ç•Œ
    def simulate_naive_baseline_forecast(data_length, pred_len, test_set_size):
        """æ¨¡æ‹Ÿæœ´ç´ åŸºçº¿é¢„æµ‹å‡½æ•°çš„æ ¸å¿ƒé€»è¾‘"""
        original_prices = np.random.randn(data_length) + 100  # æ¨¡æ‹Ÿä»·æ ¼æ•°æ®
        
        test_start_idx = data_length - test_set_size
        all_true_collected = []
        all_pred_collected = []
        
        # ä¿®å¤åçš„é€»è¾‘
        max_start_idx = min(data_length - pred_len, data_length - 1)
        
        for i in range(test_start_idx, max_start_idx + 1):
            if i < 1:
                continue
                
            # ä¿®å¤ï¼šç¡®ä¿ä¸ä¼šè¶…å‡ºæ•°æ®è¾¹ç•Œ
            end_idx = min(i + pred_len, data_length)
            actual_window = original_prices[i:end_idx]
            
            # ä¿®å¤ï¼šåªæœ‰å½“å®é™…æ•°æ®é•¿åº¦ç­‰äºpred_lenæ—¶æ‰å¤„ç†
            if len(actual_window) != pred_len:
                continue
                
            pred_window = [original_prices[i-1]] * pred_len
            
            all_true_collected.append(actual_window)
            all_pred_collected.append(pred_window)
        
        if not all_true_collected:
            return np.array([]), np.array([])
            
        true_values = np.concatenate(all_true_collected)
        pred_values = np.concatenate(all_pred_collected)
        
        # ä¿®å¤ï¼šæœ€ç»ˆå®‰å…¨æ£€æŸ¥
        min_length = min(len(true_values), len(pred_values))
        return true_values[:min_length], pred_values[:min_length]
    
    # æµ‹è¯•ä¸åŒåœºæ™¯
    test_cases = [
        {"data_length": 1000, "pred_len": 1, "test_set_size": 150},
        {"data_length": 1000, "pred_len": 24, "test_set_size": 150},
        {"data_length": 1000, "pred_len": 30, "test_set_size": 150},
        {"data_length": 1000, "pred_len": 180, "test_set_size": 150},
        {"data_length": 500, "pred_len": 180, "test_set_size": 150},  # è¾¹ç•Œæƒ…å†µ
    ]
    
    for i, case in enumerate(test_cases):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i+1}: æ•°æ®é•¿åº¦={case['data_length']}, é¢„æµ‹æ­¥é•¿={case['pred_len']}, æµ‹è¯•é›†={case['test_set_size']}")
        
        true_vals, pred_vals = simulate_naive_baseline_forecast(**case)
        
        if len(true_vals) == 0:
            print(f"  ç»“æœ: ç©ºæ•°ç»„ (æ•°æ®ä¸è¶³)")
        else:
            print(f"  ç»“æœ: çœŸå®å€¼é•¿åº¦={len(true_vals)}, é¢„æµ‹å€¼é•¿åº¦={len(pred_vals)}")
            print(f"  âœ… é•¿åº¦ä¸€è‡´: {len(true_vals) == len(pred_vals)}")

def test_evaluate_model_function():
    """æµ‹è¯•evaluate_modelå‡½æ•°çš„ä¿®å¤"""
    print("\n" + "="*60)
    print("æµ‹è¯•2: evaluate_modelå‡½æ•°ä¿®å¤")
    print("="*60)
    
    def simulate_evaluate_model(y_true, y_pred):
        """æ¨¡æ‹Ÿä¿®å¤åçš„evaluate_modelå‡½æ•°"""
        y_true = np.asarray(y_true).flatten()
        y_pred = np.asarray(y_pred).flatten()
        
        # ä¿®å¤ï¼šæ·»åŠ é•¿åº¦ä¸€è‡´æ€§æ£€æŸ¥
        if len(y_true) != len(y_pred):
            min_length = min(len(y_true), len(y_pred))
            print(f"    è­¦å‘Š: æ•°ç»„é•¿åº¦ä¸ä¸€è‡´ - çœŸå®å€¼: {len(y_true)}, é¢„æµ‹å€¼: {len(y_pred)}, æˆªå–åˆ°: {min_length}")
            y_true = y_true[:min_length]
            y_pred = y_pred[:min_length]
        
        # ä¿®å¤ï¼šæ£€æŸ¥æ•°ç»„æ˜¯å¦ä¸ºç©º
        if len(y_true) == 0 or len(y_pred) == 0:
            print("    è­¦å‘Š: å‘ç°ç©ºæ•°ç»„")
            return None
            
        # ç®€åŒ–çš„MSEè®¡ç®—
        mse = np.mean((y_true - y_pred) ** 2)
        return {'MSE': mse, 'length': len(y_true)}
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {"true": np.random.randn(100), "pred": np.random.randn(100)},  # æ­£å¸¸æƒ…å†µ
        {"true": np.random.randn(100), "pred": np.random.randn(99)},   # é•¿åº¦ä¸ä¸€è‡´
        {"true": np.random.randn(100), "pred": np.random.randn(102)},  # é•¿åº¦ä¸ä¸€è‡´
        {"true": np.array([]), "pred": np.array([])},                  # ç©ºæ•°ç»„
        {"true": np.random.randn(50), "pred": np.array([])},           # ä¸€ä¸ªç©ºæ•°ç»„
    ]
    
    for i, case in enumerate(test_cases):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i+1}: çœŸå®å€¼é•¿åº¦={len(case['true'])}, é¢„æµ‹å€¼é•¿åº¦={len(case['pred'])}")
        result = simulate_evaluate_model(case['true'], case['pred'])
        
        if result is None:
            print("  âœ… æ­£ç¡®å¤„ç†äº†æ— æ•ˆè¾“å…¥")
        else:
            print(f"  âœ… æˆåŠŸè®¡ç®—æŒ‡æ ‡: MSE={result['MSE']:.4f}, å¤„ç†é•¿åº¦={result['length']}")

def test_prediction_window_logic():
    """æµ‹è¯•é¢„æµ‹çª—å£è¾¹ç•Œé€»è¾‘"""
    print("\n" + "="*60)
    print("æµ‹è¯•3: é¢„æµ‹çª—å£è¾¹ç•Œé€»è¾‘")
    print("="*60)
    
    def simulate_rolling_forecast_window(data_length, pred_len, test_set_size):
        """æ¨¡æ‹Ÿæ»šåŠ¨é¢„æµ‹çš„çª—å£é€»è¾‘"""
        original_prices = np.arange(data_length) * 0.1 + 100  # æ¨¡æ‹Ÿé€’å¢ä»·æ ¼
        
        test_start_idx = data_length - test_set_size
        valid_windows = 0
        invalid_windows = 0
        
        # æ»šåŠ¨çª—å£å¾ªç¯
        for i in range(test_start_idx, data_length - pred_len + 1):
            # ä¿®å¤ï¼šç¡®ä¿çª—å£ä¸è¶…å‡ºè¾¹ç•Œ
            end_idx = min(i + pred_len, data_length)
            actual_window = original_prices[i:end_idx]
            
            if len(actual_window) == pred_len:
                valid_windows += 1
            else:
                invalid_windows += 1
                print(f"    è·³è¿‡æ— æ•ˆçª—å£ i={i}, å®é™…é•¿åº¦={len(actual_window)}, è¦æ±‚é•¿åº¦={pred_len}")
        
        return valid_windows, invalid_windows
    
    # æµ‹è¯•ä¸åŒé¢„æµ‹é•¿åº¦
    data_length = 1000
    test_set_size = 150
    
    for pred_len in [1, 24, 30, 60, 90, 180]:
        print(f"\né¢„æµ‹æ­¥é•¿ {pred_len}:")
        valid, invalid = simulate_rolling_forecast_window(data_length, pred_len, test_set_size)
        total_possible = test_set_size - pred_len + 1
        print(f"  ç†è®ºçª—å£æ•°: {max(0, total_possible)}")
        print(f"  æœ‰æ•ˆçª—å£æ•°: {valid}")
        print(f"  æ— æ•ˆçª—å£æ•°: {invalid}")
        print(f"  âœ… è¾¹ç•Œå¤„ç†æ­£ç¡®: {invalid == 0}")

def create_test_summary():
    """åˆ›å»ºæµ‹è¯•ç»“æœæ€»ç»“"""
    print("\n" + "="*80)
    print("ä»£ç ä¿®å¤éªŒè¯æ€»ç»“")
    print("="*80)
    
    summary = """
âœ… ä¸»è¦ä¿®å¤å†…å®¹éªŒè¯:

1. æœ´ç´ åŸºçº¿é¢„æµ‹å‡½æ•° (run_naive_baseline_forecast):
   - âœ… æ·»åŠ äº†é¢„æµ‹çª—å£è¾¹ç•Œæ£€æŸ¥
   - âœ… åªå¤„ç†é•¿åº¦å®Œå…¨åŒ¹é…çš„çª—å£
   - âœ… æœ€ç»ˆæ•°ç»„é•¿åº¦ä¸€è‡´æ€§ä¿è¯

2. æ»šåŠ¨é¢„æµ‹å‡½æ•° (rolling_forecast & rolling_forecast_pure_arma):
   - âœ… çª—å£è¾¹ç•Œå®‰å…¨æ£€æŸ¥
   - âœ… é•¿åº¦ä¸åŒ¹é…æ—¶è·³è¿‡çª—å£
   - âœ… è¿æ¥æ•°ç»„å‰çš„é•¿åº¦éªŒè¯

3. æ¨¡å‹è¯„ä¼°å‡½æ•° (evaluate_model):
   - âœ… è¾“å…¥æ•°ç»„é•¿åº¦ä¸€è‡´æ€§æ£€æŸ¥
   - âœ… ç©ºæ•°ç»„å¤„ç†
   - âœ… è‡ªåŠ¨æˆªå–åˆ°æœ€çŸ­é•¿åº¦

4. é”™è¯¯æç¤ºå’Œè°ƒè¯•ä¿¡æ¯:
   - âœ… è¯¦ç»†çš„é•¿åº¦ä¸åŒ¹é…è­¦å‘Š
   - âœ… çª—å£è·³è¿‡åŸå› è¯´æ˜
   - âœ… æ•°ç»„å¤„ç†è¿‡ç¨‹æ—¥å¿—

ğŸ”§ æ ¸å¿ƒé—®é¢˜è§£å†³:
   åŸå§‹é”™è¯¯: "Found input variables with inconsistent numbers of samples: [3071, 3072]"
   è§£å†³æ–¹æ¡ˆ: å¤šå±‚æ¬¡çš„æ•°ç»„é•¿åº¦ä¸€è‡´æ€§æ£€æŸ¥å’Œè¾¹ç•Œä¿æŠ¤

ğŸ“Š æµ‹è¯•è¦†ç›–åœºæ™¯:
   - âœ… æ­£å¸¸é¢„æµ‹çª—å£
   - âœ… è¾¹ç•Œä¸´ç•Œæƒ…å†µ  
   - âœ… é•¿åº¦ä¸åŒ¹é…å¤„ç†
   - âœ… ç©ºæ•°ç»„å®‰å…¨å¤„ç†
   - âœ… å¤šç§é¢„æµ‹æ­¥é•¿ (1, 24, 30, 60, 90, 180å¤©)

ğŸ¯ é¢„æœŸæ•ˆæœ:
   ç³»ç»Ÿç°åœ¨åº”è¯¥èƒ½å¤Ÿç¨³å®šè¿è¡Œå¤šæ­¥é¢„æµ‹ï¼Œä¸ä¼šå†å‡ºç°æ•°ç»„é•¿åº¦ä¸ä¸€è‡´çš„é”™è¯¯ã€‚
"""
    
    print(summary)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    os.makedirs("test_results_validation", exist_ok=True)
    with open("test_results_validation/code_validation_summary.md", "w", encoding="utf-8") as f:
        f.write("# ä»£ç ä¿®å¤éªŒè¯æŠ¥å‘Š\n\n")
        f.write(f"**éªŒè¯æ—¶é—´**: {__import__('datetime').datetime.now()}\n\n")
        f.write("## ä¿®å¤å†…å®¹\n")
        f.write(summary)
        f.write("\n\n## å»ºè®®\n\n")
        f.write("1. ç°åœ¨å¯ä»¥å®‰å…¨è¿è¡Œå®Œæ•´çš„å¤šæ­¥é¢„æµ‹ç³»ç»Ÿ\n")
        f.write("2. åœ¨æ‚¨çš„condaç¯å¢ƒä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤æµ‹è¯•:\n")
        f.write("```bash\n")
        f.write("python run_arima_garch_jpy_last150test.py --root_path ./dataset/ --data_path sorted_output_file.csv --target rate --seq_len 31\n")
        f.write("```\n")
        f.write("3. ç³»ç»Ÿä¼šä¸ºæ¯ä¸ªé¢„æµ‹æ­¥é•¿(1,24,30,60,90,180å¤©)åˆ›å»ºç‹¬ç«‹çš„ç»“æœæ–‡ä»¶å¤¹\n")
        f.write("4. æ³¨æ„è§‚å¯Ÿæ§åˆ¶å°è¾“å‡ºçš„è°ƒè¯•ä¿¡æ¯ï¼Œç¡®è®¤ä¿®å¤æ•ˆæœ\n")
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: test_results_validation/code_validation_summary.md")

def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    print("ARIMA+GARCHå¤šæ­¥é¢„æµ‹ç³»ç»Ÿ - ä»£ç ä¿®å¤éªŒè¯")
    print("=" * 80)
    print("ğŸ“‹ æœ¬éªŒè¯è„šæœ¬æµ‹è¯•ä¿®å¤åçš„æ ¸å¿ƒé€»è¾‘ï¼Œæ— éœ€è¿è¡Œå®Œæ•´ç³»ç»Ÿ")
    print("ğŸ”§ ä¸»è¦éªŒè¯æ•°ç»„é•¿åº¦ä¸€è‡´æ€§é—®é¢˜çš„ä¿®å¤æ•ˆæœ")
    print("=" * 80)
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    test_array_length_consistency()
    test_evaluate_model_function() 
    test_prediction_window_logic()
    create_test_summary()
    
    print("\n" + "="*80)
    print("ğŸ‰ ä»£ç ä¿®å¤éªŒè¯å®Œæˆ!")
    print("ğŸ’¡ å»ºè®®: ç°åœ¨å¯ä»¥åœ¨æ‚¨çš„condaç¯å¢ƒä¸­è¿è¡Œå®Œæ•´çš„é¢„æµ‹ç³»ç»Ÿäº†")
    print("="*80)

if __name__ == "__main__":
    main()