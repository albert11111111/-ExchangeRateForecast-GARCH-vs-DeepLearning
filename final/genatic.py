import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from deap import base, creator, tools
import random

# ========== æ•°æ®å‡†å¤‡ ==========
import os
# ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
data_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "final", "ukcndata.csv")
data = pd.read_csv(data_path, parse_dates=['Date'], index_col='Date')
rates = data['Rate'].values

scaler = MinMaxScaler(feature_range=(0, 1))
rates_scaled = scaler.fit_transform(rates.reshape(-1, 1))

def create_dataset(data, time_step=30):
    X, y = [], []
    for i in range(len(data) - time_step):
        X.append(data[i:(i + time_step), 0])
        y.append(data[i + time_step, 0])
    return np.array(X), np.array(y)

X, y = create_dataset(rates_scaled)
# âš ï¸ å‰é¦ˆç½‘ç»œä¸éœ€è¦ reshape ä¸º 3Dï¼
# X: (samples, time_steps), y: (samples,)
print(f"X shape: {X.shape}, y shape: {y.shape}")

# ========== æ„å»ºå‰é¦ˆç½‘ç»œæ¨¡å‹ ==========
def create_ffn_model(input_dim, num_layers, num_neurons, learning_rate):
    model = Sequential()
    model.add(Dense(num_neurons, input_dim=input_dim, activation='relu'))
    for _ in range(num_layers - 1):
        model.add(Dense(num_neurons, activation='relu'))
    model.add(Dense(1))
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')
    return model

# ========== é—ä¼ ç®—æ³•è®¾ç½® ==========
creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
creator.create("Individual", list, fitness=creator.FitnessMin)
toolbox = base.Toolbox()

# ä¸ªä½“åŸºå› å®šä¹‰ï¼šå±‚æ•°ï¼ˆ1~3ï¼‰ï¼ŒèŠ‚ç‚¹æ•°ï¼ˆ4~64ï¼‰ï¼Œå­¦ä¹ ç‡ï¼ˆ0.001~0.1ï¼‰
toolbox.register("attr_num_layers", random.randint, 1, 3)
toolbox.register("attr_num_neurons", random.randint, 4, 64)
toolbox.register("attr_learning_rate", random.uniform, 0.001, 0.1)
toolbox.register("individual", tools.initCycle, creator.Individual,
                 (toolbox.attr_num_layers, toolbox.attr_num_neurons, toolbox.attr_learning_rate), n=1)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

# é€‚åº”åº¦å‡½æ•°ï¼ˆä½¿ç”¨ AELï¼‰
def evaluate(individual):
    num_layers = int(round(individual[0]))
    num_neurons = int(round(individual[1]))
    learning_rate = float(individual[2])

    # åˆç†èŒƒå›´æ§åˆ¶
    num_layers = max(1, min(3, num_layers))
    num_neurons = max(4, min(128, num_neurons))
    learning_rate = max(0.0001, min(0.1, learning_rate))

    try:
        model = create_ffn_model(X.shape[1], num_layers, num_neurons, learning_rate)
        model.fit(X, y, epochs=10, batch_size=32, verbose=0)
        predictions = model.predict(X).reshape(-1)

        # å…³é”®ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å« NaN
        if np.any(np.isnan(predictions)) or np.any(np.isinf(predictions)):
            return (np.inf,)  # ç»™ä¸€ä¸ªæå¤§æƒ©ç½šï¼Œé¿å…ç¨‹åºæŠ¥é”™

        ael = mean_absolute_error(y, predictions)
        return (ael,)

    except Exception as e:
        print(f"Evaluation error: {e}")
        return (np.inf,)  # å‡ºé”™çš„ä¸ªä½“é€‚åº”åº¦è®¾ä¸ºæœ€å·®



toolbox.register("evaluate", evaluate)
toolbox.register("mate", tools.cxTwoPoint)
toolbox.register("mutate", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)

# ========== è¿è¡Œé—ä¼ ç®—æ³• ==========
population = toolbox.population(n=10)
NGEN = 30
CXPB, MUTPB = 0.7, 0.2

best_fitness_per_gen = []

# Early stopping å‚æ•°
early_stop_patience = 3      # è¿ç»­å¤šå°‘ä»£æ— æ˜æ˜¾æå‡å°±åœæ­¢
early_stop_threshold = 1e-6    # å·®å¼‚å°äºè¿™ä¸ªå€¼è®¤ä¸ºæ— æå‡
no_improve_counter = 0         # è¿ç»­æ— æå‡ä»£æ•°
best_so_far = np.inf           # å½“å‰æœ€ä¼˜é€‚åº”åº¦


for gen in range(NGEN):
    print(f"Generation {gen+1}")
    
    # è¯„ä¼°é€‚åº”åº¦
    fitnesses = list(map(toolbox.evaluate, population))
    for ind, fit in zip(population, fitnesses):
        ind.fitness.values = fit

    # è®°å½•å½“å‰ä»£çš„æœ€ä¼˜é€‚åº”åº¦
    best_fitness = min([ind.fitness.values[0] for ind in population])
    best_fitness_per_gen.append(best_fitness)
    print(f"  Best fitness: {best_fitness:.5f}")

    # é€‰æ‹©ã€å¤åˆ¶
    offspring = toolbox.select(population, len(population))
    offspring = list(map(toolbox.clone, offspring))

    # äº¤å‰
    for child1, child2 in zip(offspring[::2], offspring[1::2]):
        if random.random() < CXPB:
            toolbox.mate(child1, child2)
            del child1.fitness.values
            del child2.fitness.values

    # å˜å¼‚
    for mutant in offspring:
        if random.random() < MUTPB:
            toolbox.mutate(mutant)
            del mutant.fitness.values

    # è¯„ä¼°æ–°ä¸ªä½“
    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
    fitnesses = list(map(toolbox.evaluate, invalid_ind))
    for ind, fit in zip(invalid_ind, fitnesses):
        ind.fitness.values = fit

    population[:] = offspring
    # Early stopping åˆ¤æ–­é€»è¾‘
    if best_fitness < best_so_far - early_stop_threshold:
        best_so_far = best_fitness
        no_improve_counter = 0
    else:
        no_improve_counter += 1
        print(f"  No significant improvement for {no_improve_counter} generations")

    if no_improve_counter >= early_stop_patience:
        print(f"\nğŸ›‘ Early stopping: No improvement in {early_stop_patience} generations.")
        break


# # ========== å¯è§†åŒ–æ”¶æ•›æ›²çº¿ ==========
# plt.plot(best_fitness_per_gen, marker='o')
# plt.xlabel("Generation")
# plt.ylabel("Best Fitness (AEL)")
# plt.title("Convergence Curve of GANN (Feedforward Network)")
# plt.grid(True)
# plt.tight_layout()
# plt.show()

# ä»æœ€ç»ˆç§ç¾¤ä¸­é€‰æ‹©é€‚åº”åº¦æœ€å¥½çš„ä¸ªä½“
best_ind = tools.selBest(population, 1)[0]
num_layers = int(round(best_ind[0]))
num_neurons = int(round(best_ind[1]))
learning_rate = float(best_ind[2])

# é‡æ–°è®­ç»ƒæ¨¡å‹
model = create_ffn_model(X.shape[1], num_layers, num_neurons, learning_rate)
model.fit(X, y, epochs=50, batch_size=32, verbose=0)
pred = model.predict(X).reshape(-1)

import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# å®‰å…¨æ£€æŸ¥
if np.any(np.isnan(pred)) or np.any(np.isnan(y)):
    print("âŒ é”™è¯¯ï¼šè¾“å…¥ä¸­åŒ…å« NaNï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡")
else:
    # MAPE è¦æ±‚ä¸èƒ½é™¤ä»¥ 0
    mask = y != 0
    mape = np.mean(np.abs((y[mask] - pred[mask]) / y[mask])) * 100 if np.any(mask) else np.nan

    aae = mean_absolute_error(y, pred)
    mse = mean_squared_error(y, pred)
    max_ae = np.max(np.abs(y - pred))
    r_sq = r2_score(y, pred)

    print("\nğŸ“Š Final Model Evaluation Metrics:")
    print(f"AAE      : {aae:.6f}")
    print(f"MAPE (%) : {mape:.5f}")
    print(f"MSE      : {mse:.6e}")
    print(f"Max AE   : {max_ae:.5f}")
    print(f"R-SQ     : {r_sq:.5f}")
